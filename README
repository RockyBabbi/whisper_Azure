# Audio/Video Transcription with OpenAI Whisper

This project is a Streamlit application that allows users to upload audio or video files for transcription using the OpenAI Whisper API. The application supports various audio formats, including MP3, WAV, M4A, and MP4.

## Features

- Upload audio/video files for transcription
- Displays the transcribed text from the uploaded file
- Utilizes Azure OpenAI Service for audio transcription

## Prerequisites

- Python 3.7 or higher
- Streamlit
- OpenAI Python client library
- `python-dotenv` for loading environment variables

## Installation

1. Clone the repository:

   git clone https://github.com/yourusername/repo-name.git
   cd repo-name

2. Create a virtual environment and activate it:

   python -m venv venv
   # On Windows
   venv\Scripts\activate
   # On macOS/Linux
   source venv/bin/activate

3. Install the required packages:

   pip install -r requirements.txt

4. Create a .env file in the project root and add your OpenAI API credentials:

   OPENAI_API_TYPE=azure
   AZURE_OPENAI_ENDPOINT=your_endpoint
   OPENAI_API_KEY=your_api_key
   OPENAI_API_VERSION=your_api_version
   AZURE_DEPLOYMENT_ID=your_deployment_id

Usage
   1.   Run the Streamlit application: streamlit run app.py
   2.   open your web browser and navigate to http://localhost:8501.
   3.   Upload an audio or video file, and the application will display the transcription.

Notes
-   Ensure that the C:\whisper directory exists or is created automatically by the application to store uploaded files.
-   The application handles common audio/video formats but may need adjustments for other formats.
